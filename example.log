INFO run-main-0 com.example.Hello - This application is build with the sbt tool
DEBUG run-main-0 org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:326)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:351)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2823)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2818)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2684)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:172)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:357)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)
	at org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:209)
	at org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:266)
	at org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:217)
	at org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:183)
	at org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:153)
	at org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:119)
	at org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:92)
	at org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:66)
	at org.apache.parquet.hadoop.ParquetWriter.<init>(ParquetWriter.java:232)
	at com.example.CsvParquetWriter.<init>(CsvParquetWriter.java:15)
	at com.example.Hello.main(Hello.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at sbt.Run.invokeMain(Run.scala:67)
	at sbt.Run.run0(Run.scala:61)
	at sbt.Run.sbt$Run$$execute$1(Run.scala:51)
	at sbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Logger$$anon$4.apply(Logger.scala:85)
	at sbt.TrapExit$App.run(TrapExit.scala:248)
	at java.lang.Thread.run(Thread.java:745)
DEBUG run-main-0 org.apache.hadoop.util.Shell - setsid exited with exit code 0
DEBUG run-main-0 org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
DEBUG run-main-0 org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
DEBUG run-main-0 org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, valueName=Time, value=[GetGroups])
DEBUG run-main-0 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG run-main-0 org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG run-main-0 org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG run-main-0 org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG run-main-0 org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG run-main-0 org.apache.hadoop.util.NativeCodeLoader - java.library.path=/home/greatdreams/softwares/idea-IU-162.1121.32/bin::/home/greatdreams/tomcat-native-1.2.8/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
WARN run-main-0 org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG run-main-0 org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG run-main-0 org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG run-main-0 org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG run-main-0 org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG run-main-0 org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG run-main-0 org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: greatdreams
DEBUG run-main-0 org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: greatdreams" with name greatdreams
DEBUG run-main-0 org.apache.hadoop.security.UserGroupInformation - User entry: "greatdreams"
DEBUG run-main-0 org.apache.hadoop.security.UserGroupInformation - UGI loginUser:greatdreams (auth:SIMPLE)
WARN org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner org.apache.hadoop.fs.FileSystem - exception in the cleaner thread but it will continue to run
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:142)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:158)
	at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:3063)
	at java.lang.Thread.run(Thread.java:745)
